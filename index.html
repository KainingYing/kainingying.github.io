<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="pic/assets/fudan.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Kaining Ying, CS, FDU, Fudan University">
<meta name="description" content="Kaining Ying&#39;s home page">

<meta name="google-site-verification" content="xg04VgCH_1GseFDVDJUDOU2fWPkMU61koxePfxI9L2U" />
<meta name="msvalidate.01" content="E97E87F9D2EF3C50E40066873E89A005" />

<link rel="stylesheet" href="css/jemdoc.css" type="text/css">
<style>
h1, h2, h3, h4, h5, h6 {
    color: black !important;
}

.pub-button {
    background: #f0f0f0;
    color: #666;
    border: none;
    padding: 8px 16px;
    margin-right: 8px;
    border-radius: 20px;
    cursor: pointer;
    font-size: 14px;
    font-weight: 500;
    transition: all 0.3s ease;
}

.pub-button:hover {
    background: #e0e0e0;
    transform: translateY(-1px);
    box-shadow: 0 2px 8px rgba(0,0,0,0.15);
}

.pub-button.active {
    background: #2c5aa0 !important;
    color: white !important;
}

.pub-button.active:hover {
    background: #1e3f73 !important;
}

#pubs li > div:first-child, 
#pubs_all li > div:first-child {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
    font-variant-numeric: lining-nums !important;
    font-feature-settings: "lnum" 1, "onum" 0 !important;
    font-weight: 560;
}

#pubs li, 
#pubs_all li {
    line-height: 1.2;
    margin-bottom: 16px;
}

#pubs li > div, 
#pubs_all li > div {
    margin-bottom: 4px;
}

.venue {
    font-weight: 600;
    font-style: italic;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
    font-variant-numeric: lining-nums !important;
    font-feature-settings: "lnum" 1, "onum" 0 !important;
}

.venue-highlight {
    background: linear-gradient(120deg, #ff6b6b 0%, #ffd93d 100%);
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 12px;
    font-weight: 600;
    color: #333;
    margin-left: 8px;
}

#pubs a,
#pubs_all a {
    color: #0066cc !important;
    text-decoration: none;
    font-weight: 500;
}

#pubs a:hover,
#pubs_all a:hover {
    color: #004499 !important;
    text-decoration: underline;
}

#pubs a:visited,
#pubs_all a:visited {
    color: #0066cc !important;
}

.bibtex-modal {
    display: none;
    position: fixed;
    z-index: 1000;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(0, 0, 0, 0.5);
    animation: fadeIn 0.3s ease-out;
}

.bibtex-modal-content {
    background-color: white;
    margin: 5% auto;
    padding: 20px;
    border: none;
    border-radius: 8px;
    width: 80%;
    max-width: 800px;
    max-height: 80%;
    overflow-y: auto;
    position: relative;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
    animation: slideIn 0.3s ease-out;
}

.bibtex-modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 20px;
    border-bottom: 1px solid #eee;
    padding-bottom: 15px;
}

.bibtex-modal-header h3 {
    margin: 0;
    color: #333;
    font-size: 24px;
}

.bibtex-close {
    background: #f0f0f0;
    border: none;
    border-radius: 50%;
    width: 40px;
    height: 40px;
    font-size: 24px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.3s ease;
}

.bibtex-close:hover {
    background: #e0e0e0;
    transform: scale(1.1);
}

.bibtex-content {
    background: #f8f9fa;
    border: 1px solid #e9ecef;
    border-radius: 6px;
    padding: 20px;
    font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', monospace;
    font-size: 14px;
    line-height: 1.5;
    white-space: pre-wrap;
    overflow-x: auto;
    margin-bottom: 20px;
    color: #495057;
}

.bibtex-actions {
    display: flex;
    gap: 12px;
    justify-content: flex-end;
}

.bibtex-copy-btn, 
.bibtex-download-btn {
    background: #2c5aa0;
    color: white;
    border: none;
    padding: 10px 20px;
    border-radius: 6px;
    cursor: pointer;
    font-size: 14px;
    font-weight: 500;
    transition: all 0.3s ease;
}

.bibtex-copy-btn:hover, 
.bibtex-download-btn:hover {
    background: #1e3f73;
    transform: translateY(-1px);
    box-shadow: 0 2px 8px rgba(0,0,0,0.15);
}

.bibtex-download-btn {
    background: #6c757d;
}

.bibtex-download-btn:hover {
    background: #545b62;
}

.copy-success {
    background: #28a745 !important;
}

@keyframes fadeIn {
    from { opacity: 0; }
    to { opacity: 1; }
}

@keyframes slideIn {
    from { 
        opacity: 0;
        transform: translateY(-50px);
    }
    to { 
        opacity: 1;
        transform: translateY(0);
    }
}
</style>
<title>Kaining Ying&#39;s Homepage</title>

<script>
let selectedPubsContent = '';

function showPubs(id) {
  if (id == 0) {
    document.getElementById('pubs').innerHTML = selectedPubsContent;
    document.getElementById('select0').className = 'pub-button active';
    document.getElementById('select1').className = 'pub-button';
  } else {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_all').innerHTML;
    document.getElementById('select0').className = 'pub-button';
    document.getElementById('select1').className = 'pub-button active';
  }
}

function showBibTeX(bibFile, title) {
  fetch(bibFile)
    .then(response => {
      if (!response.ok) {
        throw new Error('Network response was not ok');
      }
      return response.text();
    })
    .then(data => {
      const modal = document.getElementById('bibtex-modal');
      const titleElement = document.getElementById('bibtex-title');
      const contentElement = document.getElementById('bibtex-content');
      
      titleElement.textContent = title;
      contentElement.textContent = data;
      modal.style.display = 'block';
      
      modal.bibContent = data;
      modal.bibFilename = bibFile.split('/').pop();
    })
    .catch(error => {
      console.error('Error fetching BibTeX:', error);
      alert('无法加载BibTeX文件，请稍后重试。');
    });
}

function closeBibTeX() {
  document.getElementById('bibtex-modal').style.display = 'none';
}

function copyBibTeX() {
  const modal = document.getElementById('bibtex-modal');
  const copyBtn = document.querySelector('.bibtex-copy-btn');
  
  navigator.clipboard.writeText(modal.bibContent)
    .then(() => {
      showCopySuccess(copyBtn);
    })
    .catch(err => {
      console.error('复制失败:', err);
      fallbackCopyText(modal.bibContent);
      showCopySuccess(copyBtn);
    });
}

function showCopySuccess(button) {
  const originalText = button.textContent;
  button.textContent = '已复制!';
  button.classList.add('copy-success');
  
  setTimeout(() => {
    button.textContent = originalText;
    button.classList.remove('copy-success');
  }, 2000);
}

function fallbackCopyText(text) {
  const textArea = document.createElement('textarea');
  textArea.value = text;
  document.body.appendChild(textArea);
  textArea.select();
  document.execCommand('copy');
  document.body.removeChild(textArea);
}

function downloadBibTeX() {
  const modal = document.getElementById('bibtex-modal');
  const blob = new Blob([modal.bibContent], { type: 'text/plain' });
  const url = window.URL.createObjectURL(blob);
  const a = document.createElement('a');
  
  a.href = url;
  a.download = modal.bibFilename;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  window.URL.revokeObjectURL(url);
}

window.onclick = function(event) {
  const modal = document.getElementById('bibtex-modal');
  if (event.target === modal) {
    closeBibTeX();
  }
}

document.addEventListener('keydown', function(event) {
  if (event.key === 'Escape') {
    closeBibTeX();
  }
});

window.onload = function() {
  selectedPubsContent = document.getElementById('pubs').innerHTML;
  showPubs(0);
}
</script>
</head>
<body>

<div id="bibtex-modal" class="bibtex-modal">
  <div class="bibtex-modal-content">
    <div class="bibtex-modal-header">
      <h3 id="bibtex-title">BibTeX Citation</h3>
      <button class="bibtex-close" onclick="closeBibTeX()">&times;</button>
    </div>
    <div id="bibtex-content" class="bibtex-content"></div>
    <div class="bibtex-actions">
      <button class="bibtex-copy-btn" onclick="copyBibTeX()">Copy</button>
      <button class="bibtex-download-btn" onclick="downloadBibTeX()">Download</button>
    </div>
  </div>
</div>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
		<td width="65%">
			<div id="toptitle">
				<h1>Kaining Ying <font face="Arial">应凯宁</font></h1>
			</div>
		Ph.D. Student
		<p>Fudan University</br></br>
		Email: kaining.ying.cv [at] gmail [dot] com</br>
		</p>
		<p>
			<a href="https://github.com/KainingYing" target="_blank"><img src="pic/assets/github_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?user=MDvaeqUAAAAJ&hl=en" target="_blank"><img src="pic/assets/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;
		</p>
			</td>

			</td>
			<td width="35%">
				<img src="pic/kaining_selfie.jpg" width="100%"/>
			</td>
		<tr>
	</tbody>
</table>


<h2>Biography </h2>
<p>
	I'm a second-year Ph.D. student jointly at 
	<a href="https://cs.fudan.edu.cn" target="_blank">College of Computer Science and Artificial Intelligence</a>@<a href="https://www.fudan.edu.cn" target="_blank">Fudan University</a>, 
	advised by Prof. <a href="https://henghuiding.com" target="_blank">Henghui Ding</a>. 
	<br>
	<br>
	My research interests include computer vision, multimodal learning.
</p>


<h2>News</h2>
<ul>
  <li>
		[08/2025] <a href="https://mose.video" target="_blank">MOSEv2</a> is released. Checkout the <a href="https://arxiv.org/abs/2508.05630" target="_blank">report</a>, <a href="https://www.codabench.org/competitions/10062/" target="_blank">dataset</a>, and <a href="https://github.com/henghuiding/MOSE-api" target="_blank">code</a>.
	</li>
  <li>
		[08/2025] One co-authored paper is accepted by TPAMI.
	</li>
	<li>
		[06/2025] Two first-authored papers are accepted by ICCV 2025.
	</li>
</ul>

<h2>Publications</h2>
<div style="margin-bottom: 15px;">
	<div style="display: flex; align-items: center; flex-wrap: wrap; gap: 12px;">
		<div>
			<button id="select0" onclick="showPubs(0)" class="pub-button active">Selected (Ph.D. Period)</button>
			<button id="select1" onclick="showPubs(1)" class="pub-button">Full List</button>
		</div>
		<div style="color: #666; font-size: 14px;">(*equal contribution)</div>
	</div>
</div>

<div id="pubs">
	<ul>
		<li>
			<div >MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes</div>
			<div >Henghui Ding*, <b>Kaining Ying</b>*, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H. S. Torr, Song Bai</div>
			<div ><span class="venue">arXiv 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</div>
			<div >Henghui Ding, Chang Liu, Shuting He, <b>Kaining Ying</b>, Xudong Jiang, Chen Change Loy, Yu-Gang Jiang</div>
			<div ><span class="venue">IEEE Trans. Pattern Analysis and Machine Intelligence (TPAMI) 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MOVE: Motion-Guided Few-Shot Video Object Segmentation</div>
			<div ><b>Kaining Ying</b>*, Hengrui Hu*, Henghui Ding</div>
			<div ><span class="venue">ICCV 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation</div>
			<div ><b>Kaining Ying</b>, Henghui Ding, Guangquan Jie, Yu-Gang Jiang</div>
			<div ><span class="venue">ICCV 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
	</ul>
</div>

<div id="pubs_all" style="display: none;">
	<ul>
		<li>
			<div >Segment Anything Across Shots: A Method and Benchmark</div>
			<div >Hengrui Hu, <b>Kaining Ying</b>, Henghui Ding</div>
			<div ><span class="venue">Paper 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes</div>
			<div >Henghui Ding*, <b>Kaining Ying</b>*, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H. S. Torr, Song Bai</div>
			<div ><span class="venue">Paper 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</div>
			<div >Henghui Ding, Chang Liu, Shuting He, <b>Kaining Ying</b>, Xudong Jiang, Chen Change Loy, Yu-Gang Jiang</div>
			<div ><span class="venue">IEEE Trans. Pattern Analysis and Machine Intelligence (TPAMI) 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MOVE: Motion-Guided Few-Shot Video Object Segmentation</div>
			<div ><b>Kaining Ying</b>*, Hengrui Hu*, Henghui Ding</div>
			<div ><span class="venue">ICCV 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation</div>
			<div ><b>Kaining Ying</b>, Henghui Ding, Guangyao Jie, Yu-Gang Jiang</div>
			<div ><span class="venue">ICCV 2025</span></div>
			<div>[Paper]
			[Code]
			[BibTeX]</div>
		</li>
    <div style="text-align: center; margin: 20px 0; position: relative;">
			<hr style="border: none; border-top: 1px solid #ccc;">
			<span style="background: white; padding: 0 15px; color: #666; font-size: 14px; position: absolute; top: -8px; left: 50%; transform: translateX(-50%);">Ph.D. Period ↑</span>
		</div>
		<li>
			<div >ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Capability for Large Vision-Language Models</div>
			<div >Shuo Liu, <b>Kaining Ying</b>, Hao Zhang, Yue Yang, Yuqi Lin, Tianle Zhang, Chuanhao Li, Yu Qiao, Ping Luo, Wenqi Shao, Kaipeng Zhang</div>
			<div ><span class="venue">NeurIPS 2024</span><span class="venue-highlight">Spotlight</span></div>
			<div>[<a href="https://arxiv.org/abs/2403.20194" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI</div>
			<div ><b>Kaining Ying</b>, Fanqing Meng, Jin Wang, Zhiqian Li, Han Lin, Yue Yang, Hao Zhang, Wenbo Zhang, Yuqi Lin, Shuo Liu, Jiayi Lei, Quanfeng Lu, Runjian Chen, Peng Xu, Renrui Zhang, Haozhe Zhang, Peng Gao, Yali Wang, Yu Qiao, Ping Luo, Kaipeng Zhang, Wenqi Shao</div>
			<div ><span class="venue">ICML 2024</span></div>
			<div>[<a href="https://proceedings.mlr.press/v235/ying24a.html" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >Human-to-Human Interaction Detection</div>
			<div ><b>Kaining Ying</b>, Zhenhua Wang, Jiajun Meng, Jifeng Ning</div>
			<div ><span class="venue">ICONIP 2023</span><span class="venue-highlight">Oral</span></div>
			<div>[<a href="https://link.springer.com/chapter/10.1007/978-981-99-8070-3_10" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >CTVIS: Consistent Training for Online Video Instance Segmentation</div>
			<div ><b>Kaining Ying</b>*, Qing Zhong*, Weian Mao, Zhenhua Wang, Hao Chen, Lin Yuanbo Wu, Yifan Liu, Chengxiang Fan, Yunzhi Zhuge, Chunhua Shen</div>
			<div ><span class="venue">ICCV 2023</span></div>
			<div>[<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.html" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >Human Interaction Understanding with Consistency-Aware Learning</div>
			<div >Jiajun Meng, Zhenhua Wang, <b>Kaining Ying</b>, Jianhua Zhang, Dongyan Guo, Zheng Zhang, Qinfeng Shi, Shengyong Chen</div>
			<div ><span class="venue">IEEE Trans. Pattern Analysis and Machine Intelligence (TPAMI) 2023</span></div>
			<div>[<a href="https://ieeexplore.ieee.org/document/10138446/" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >Self-supervised Enhancement for Named Entity Disambiguation via Multimodal Graph Convolution</div>
			<div >Peng Zhou*, <b>Kaining Ying</b>*, Zhenhua Wang, Dongyan Guo, Chuncong Bai</div>
			<div ><span class="venue">IEEE Trans. on Neural Networks and Learning Systems (TNNLS) 2022</span></div>
			<div>[<a href="https://ieeexplore.ieee.org/document/9774860/" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
		<li>
			<div >ISDA: Position-Aware Instance Segmentation with Deformable Attention</div>
			<div ><b>Kaining Ying</b>, Zhenhua Wang, Cong Bai, Peng Zhou</div>
			<div ><span class="venue">ICASSP 2022</span><span class="venue-highlight">Oral</span></div>
			<div>[<a href="https://arxiv.org/abs/2202.12251" target="_blank">Paper</a>]
			[Code]
			[BibTeX]</div>
		</li>
	</ul>
</div>


<h2><font> Education </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Ph.D. Student, College of Computer Science and Artificial Intelligence, Fudan University, 2024 - Present<br>
		  Master, College of Computer Science and Technology, Zhejiang University of Technology, 2021 – 2024<br>
		  Bachelor, College of Computer Science and Technology, Zhejiang University of Technology, 2017 - 2021<br>
	  </font> </p>
</ul>

<h2><font> Experiences </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Intern in Shanghai Artificial Intelligence Laboratory, 2023 - 2024 <br>
		  Visiting Student in CAD&CG Laboratory, Zhejiang University, 2022 - 2023 <br>
	  </font> </p>
</ul>

<!-- <h2><font> Academic Activities </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Reviewer for MICCAI<br>
		  Organizer of <a href='http://amos22.grand-challenge.org/'>Abdominal Multi-Organ Segmentation Challenge</a> in MICCAI, 2022 <br>
	  </font> </p>
</ul> -->

<h2><font> Miscellaneous </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Hobbies: Playing Valorant (ID: <font face="Arial">唐氏玩家#12973</font>) with friends<br>
      Research Companions: <a href="https://weijiemax.github.io" target="_blank">Weijie Ma</a>, <a href="https://scholar.google.com/citations?user=X8U4r4YAAAAJ&hl=zh-CN" target="_blank">Hengrui Hu</a>, and more not listed.
	  </font> </p>
</ul>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<tr>
	<td>
	<br>
	<!-- <p>
		<center>
		<div id="clustrmaps-widget" style="width:100%">
		<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=KAE2DNI6TdSULh7o_SWlymdZDp12ntmLHZDHfgdpkdQ&co=2d78ad&cmo=ff0000&cmn=ffb800&ct=ffffff'></script>
		</div> 
		</center>
	</p> -->
	<p align="center">
		<font>
		&copy; Kaining Ying | Last updated: Sept 2025 | Template from <a href="https://weijiemax.github.io" target="_blank">weijiemax.github.io</a>
		</font>
	</p>
	</td>
	</tr>
</table>

</div>

</body></html>
